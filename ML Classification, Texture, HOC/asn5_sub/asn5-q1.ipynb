{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "In this question we will:\n",
    "\n",
    "- Implement and test a Histogram of Curvature Scale (HoCS) descriptor for an image.\n",
    "- Extract the HoCS descriptors for the training images in our leaf dataset.\n",
    "- Prepare a K-nearest-neighbours (KNN) classifier using the descriptors extracted from the training dataset.\n",
    "- Extract the HoCS descriptors for the test images in our leaf dataset.\n",
    "- Classify the descriptors from the test images into one of the three leaf shape classes using the KNN classifier prepared earlier.\n",
    "- Reflect on the performance of the KNN classifier and your choices of parameters for the HoCS descriptors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1:  Implement the Histogram of Curvature Scale\n",
    "\n",
    "Write a function called HoCS that returns a histogram of curvature scale feature vector for a given region.  The inputs to your function should be:\n",
    "\n",
    "- `B`: a binary that contains exactly one foreground connected component.\n",
    "- `min_scale`: The samllest scale (circle radius) at which to calcluate curvature (must be a positive integer)\n",
    "- `max_scale`: The largest scale (circle radius) at which to calculate curvature (must be an integer greater than `min_scale`)\n",
    "- `increment`: The increment at which intermediate curvatures should be calculated (must be a positive integer)\n",
    "- `num_bins`: The number of bins in the histogram of curvature for a single scale (must be a positive integer)\n",
    "\n",
    "Your function should compute a histogram of curvature for each scale, starting at `min_scale` ending at (at most) `max_scale`, and for intermediate scales at increments of `increment`.  For example, if `min_scale`=4 and `max_scale`=20, and `increment`=3, then the function should compute a histogram of curvature for scales 4, 7, 10, 13, 16, and 19.  Each histogram at each scale should have `num_bins` bins.  Curvature must be computed using the normalized area integral invariant method described on Slide 39 of the Topic 9 lecture notes.  \n",
    "\n",
    "Normalize each histogram at each scale.\n",
    "\n",
    "To keep things straightforward, your function should only consider the main boundary of the input region and ignore the boundaries of holes in the region.\n",
    "\n",
    "After computing the histogram of curvature at each of the specified scales, all of the histograms should be concatenated into a single one-dimensional array (feature vector) and then returned.\n",
    "\n",
    "_Implementation hint:  You can calculate the normalized area integral invariant of each pixel efficiently using linear filtering.  You will find the function `skimage.morphology.disk()` function useful for designing the appropriate filter masks._\n",
    "\n",
    "_Implementation hint:  Most of the heavy lifting here can be done with module functions from `skimage`, `numpy`, and `scipy`.  Many of the functions mentioned in class and in the notes will be useful.  One that we might not have covered, but will be very handy is `numpy.histogram()`.  When use use it, makes sure you specify both the `bins` and `range` optional arguments.  Also note that `numpy.histogram()` returns TWO things.  You only need the first one, so make sure you write your function call like this:_\n",
    "\n",
    "`the_histogram, stuff_you_dont_need = np.histogram(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code your HoCS function here\n",
    "import skimage.morphology as morph\n",
    "import numpy as np\n",
    "import skimage.segmentation as seg\n",
    "\n",
    "def HoCS(B, min_scale, max_scale, increment, num_bins):\n",
    "    '''\n",
    "    Computes a histogram of curvature scale for the shape in the binary image B.  \n",
    "    Boundary fragments due to holes are ignored.\n",
    "    :param B: A binary image consisting of a single foreground connected component.\n",
    "    :param min_scale: smallest scale to consider (minimum 1)\n",
    "    :param max_scale: largest scale to consider (max_scale > min_scale)\n",
    "    :param increment:  increment on which to compute scales between min_scale and max_scale\n",
    "    :param num_bins: number of bins for the histogram at each scale\n",
    "    :return: 1D array of histograms concatenated together in order of increasing scale.\n",
    "    '''\n",
    "    \n",
    "    labeled_image = morph.label(B > 0)\n",
    "    bp = np.where(seg.find_boundaries(labeled_image, connectivity=1, mode='inner') > 0)\n",
    "    boundary_points = np.transpose(np.vstack(bp))\n",
    "    \n",
    "    conc_histogram = [] \n",
    "    \n",
    "    for scale in range(min_scale, max_scale+1, increment):\n",
    "        circle_neighbourhood = morph.disk(scale)\n",
    "        kp_values = []\n",
    "        for p in boundary_points:\n",
    "            x,y = p\n",
    "            #slice a region centred on the boundary point of size same as the disk  \n",
    "            disk_region = B[\n",
    "                max(0, x - scale):min(B.shape[0], x + scale + 1),\n",
    "                max(0, y - scale):min(B.shape[1], y + scale + 1)\n",
    "                        ]\n",
    "            if disk_region.shape != circle_neighbourhood.shape:\n",
    "                cropped_disk = circle_neighbourhood[\n",
    "                        max(0, scale - x):scale + 1 + min(scale, B.shape[0] - x - 1),\n",
    "                        max(0, scale - y):scale + 1 + min(scale, B.shape[1] - y - 1)\n",
    "                        ]\n",
    "            else:\n",
    "                cropped_disk = circle_neighbourhood\n",
    "                \n",
    "            intersection = np.logical_and(disk_region, cropped_disk).sum()\n",
    "            \n",
    "            kp = intersection / cropped_disk.sum()\n",
    "            \n",
    "            kp_values.append(kp)\n",
    "            \n",
    "            the_histogram, _ = np.histogram(kp_values, bins=num_bins,range=(0, 1))\n",
    "            \n",
    "            normalized_histogram = the_histogram / np.sum(the_histogram)\n",
    "            \n",
    "        conc_histogram.extend(normalized_histogram)\n",
    "        \n",
    "    return np.array(conc_histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Test your HoCS function.\n",
    "\n",
    "Run your `HoCS()` function on `image_0001.png` from leaftraining directory.  Use `min_scale=5`, `max_scale=25`, `increment=10`, `num_bins=10`.  Plot the resulting feature vector as a bar graph.  Set the y-axis limits to be between 0.0 and 1.0.  You should get a result that matches the sample output in the assignment description.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 30 artists>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inlin\n",
    "image = HoCS(io.imread(\"/u1/cmpt487-819/data/asn5/leaftraining/image_0001.png\"),5,25,10,10)\n",
    "\n",
    "\n",
    "x = range(len(image))\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.bar(x, image, width = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Calculate training features.\n",
    "\n",
    "Use your function from Step 1 to compute the HoCS feature for each of the training images.  It is up to you to determine the parameters for the HoCS feature such as `min_scale`, `max_scale`, etc. to maximize the classification rate.  This will require some experimentation.  Slides 19-12 of Topic 12 lecture notes will be helpful here.  \n",
    "\n",
    "Also generate the training labels here (a column-array of numbers indicating which descriptors belong to each class, e.g. use values 1,2,3 to indicate class 1, 2, and 3.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30 of 30(30, 20)\n"
     ]
    }
   ],
   "source": [
    "import os as os\n",
    "import pandas as pd\n",
    "\n",
    "# read in the images listed in leaftraining.csv and compute descriptors for them using your HoCS() function.\n",
    "leaftraining_path = '/u1/cmpt487-819/data/asn5/leaftraining/'\n",
    "leaftraining_files = pd.read_csv(\"/u1/cmpt487-819/data/asn5/leaftraining.csv\", header=None)\n",
    "leaftraining_file_list = leaftraining_files[0].tolist()\n",
    "\n",
    "min_scale = 5\n",
    "max_scale = 25\n",
    "num_bins = 4\n",
    "increment = 5\n",
    "\n",
    "training_hoc_values = []\n",
    "training_labels = np.zeros(len(file_list))\n",
    "\n",
    "for i in range(len(leaftraining_file_list)):\n",
    "    if i < 10:\n",
    "        training_labels[i] = 1 \n",
    "    elif i < 20:\n",
    "        training_labels[i] = 2\n",
    "    else:\n",
    "        training_labels[i] = 3\n",
    "        \n",
    "    image_path = os.path.join(leaftraining_path, leaftraining_file_list[i])   \n",
    "    image = io.imread(image_path)\n",
    "    hoc_value  =  HoCS(image,min_scale,max_scale,increment,num_bins)\n",
    "    training_hoc_values.append(hoc_value)\n",
    "    print(f\"\\rIteration {i + 1} of {len(leaftraining_file_list)}\", end=\"\")\n",
    "\n",
    "hoc_value_array = np.array(training_hoc_values)\n",
    "print(hoc_value_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Train the KNN classifier using the feature vectors from the training images.\n",
    "\n",
    "You have another opportunity here to optimize parameters.  You can experiment with the options for the KNN classifier (in partiuclar n_neighbors) to try to obtain better classification rates.  But you won't really be able to do this until after step 6, so just use default parameters to start with. \n",
    "\n",
    "Hint: The steps in this notebook are broken up the way they are so that you can adjust the parameters of training the classifier and then go and perform the classfication without having to re-run the calculation of the features in steps 3 and 5.  You can adjust the parameters here in step 4, and then go and re-run the test set in Step 6 without running step 5 over again -- which is good because step 5 will take a while to run.  Of course you will have to recalculate the features each time you restart PyCharm or the Jupyter Notebook server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-31 {color: black;}#sk-container-id-31 pre{padding: 0;}#sk-container-id-31 div.sk-toggleable {background-color: white;}#sk-container-id-31 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-31 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-31 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-31 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-31 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-31 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-31 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-31 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-31 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-31 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-31 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-31 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-31 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-31 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-31 div.sk-item {position: relative;z-index: 1;}#sk-container-id-31 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-31 div.sk-item::before, #sk-container-id-31 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-31 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-31 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-31 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-31 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-31 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-31 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-31 div.sk-label-container {text-align: center;}#sk-container-id-31 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-31 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-31\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" checked><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.neighbors as neigh\n",
    "# Train the KNN classifier\n",
    "\n",
    "knn = neigh.KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "knn.fit(hoc_value_array,training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Calculate the testing features.\n",
    "\n",
    "Compute the HoCS features for all of the testing images using the filenames in `leaftesting.csv`.  Use the same HoCS parameters you did in Step 3.  Also generate class labels for the testing image descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 129 of 129"
     ]
    }
   ],
   "source": [
    "# use the filenames in leaftesting.csv to load each image and process it\n",
    "\n",
    "leaftesting_path = '/u1/cmpt487-819/data/asn5/leaftesting/'\n",
    "leaftesting_files = pd.read_csv(\"/u1/cmpt487-819/data/asn5/leaftesting.csv\", header=None)\n",
    "leaftesting_file_list = leaftesting_files[0].tolist()\n",
    "\n",
    "testing_hoc_values = []\n",
    "testing_labels = np.zeros(len(leaftesting_file_list))\n",
    "\n",
    "\n",
    "for i in range(len(leaftesting_file_list)):\n",
    "    if i < 50:\n",
    "        testing_labels[i] = 1 \n",
    "    elif i < 77:\n",
    "        testing_labels[i] = 2\n",
    "    else:\n",
    "        testing_labels[i] = 3\n",
    "        \n",
    "    image_path = os.path.join(leaftesting_path, leaftesting_file_list[i])   \n",
    "    image = io.imread(image_path)\n",
    "    \n",
    "    hoc_value  =  HoCS(image,min_scale,max_scale,increment,num_bins)\n",
    "    testing_hoc_values.append(hoc_value)\n",
    "    print(f\"\\rIteration {i + 1} of {len(leaftesting_file_list)}\", end=\"\")\n",
    "\n",
    "testing_hoc_value_array = np.array(testing_hoc_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Classfiy the testing features.\n",
    "\n",
    "Classify the descriptors you generated from the test images using the KNN classifier you created in Step 4.\n",
    "\n",
    "Determine the classification rate and the confusion matrix by comparing the results of the classifier to the true class labels for each image.  \n",
    "\n",
    "Print out the filenames of incorrectly classified images.\n",
    "\n",
    "Print the confusion matrix (you don't have to print the row/column indicies as in the example in the assignment description), just the rows and columns of the matrix itself.   Confusion matrix is explained in the background section of the assignment PDF document.\n",
    "\n",
    "Print the correct classification rate.  Classification rate is explained in the Topic 12 notes and in the background section of the assignment PDF document.\n",
    "\n",
    "It should be very easy to get a classficiation rate more than 90%; with well-chosen parameters for your HoCS features and the KNN classifier you should be able to get as much as 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[49  0  1]\n",
      " [ 0 27  0]\n",
      " [ 2  3 47]]\n",
      "\n",
      "Classification Rate: 95.35%\n",
      "\n",
      "Misclassified Images:\n",
      "image_0060.png | True: 1 | Predicted: 3\n",
      "image_0127.png | True: 3 | Predicted: 1\n",
      "image_0140.png | True: 3 | Predicted: 2\n",
      "image_0173.png | True: 3 | Predicted: 2\n",
      "image_0185.png | True: 3 | Predicted: 2\n",
      "image_0186.png | True: 3 | Predicted: 1\n"
     ]
    }
   ],
   "source": [
    "# Write your code for Step 6 here.\n",
    "def confusion_matrix(y_true, y_pred, num_classes):\n",
    "    \n",
    "    conf_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    \n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        conf_matrix[true - 1][pred - 1] += 1  \n",
    "    return conf_matrix\n",
    "\n",
    "testing_labels = testing_labels.astype(int)\n",
    "predicted_labels = knn.predict(testing_hoc_value_array).astype(int)\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(testing_labels, predicted_labels,3)\n",
    "\n",
    "correct_classifications = np.trace(conf_matrix)\n",
    "total_samples = np.sum(conf_matrix)\n",
    "classification_rate = correct_classifications / total_samples * 100\n",
    "\n",
    "misclassified_indices = np.where(testing_labels != predicted_labels)[0]\n",
    "misclassified_files = [leaftesting_file_list[i] for i in misclassified_indices]\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nClassification Rate: {:.2f}%\".format(classification_rate))\n",
    "\n",
    "print(\"\\nMisclassified Images:\")\n",
    "for idx in misclassified_indices:\n",
    "    print(f\"{leaftesting_file_list[idx]} | True: {testing_labels[idx]} | Predicted: {predicted_labels[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Reflections\n",
    "\n",
    "Answer the following questions right here in this block:\n",
    "\n",
    "- Discuss your HoCS parameters and how you arrived at them.  Why did you choose the scales and number of histogram bins that you did?  Are there other values that work just as well?   Likely you tested other HoCS parameters that resulted in worse performance before finding the ones that worked best -- what were some of them and why do you think the performance was worse?\n",
    "\n",
    "\t_Your answer:_\t•\tI tested several combinations of min_scale, max_scale, increment, and num_bins to optimize the classification rate. The final optimal parameters I selected were:\n",
    "\t•\tmin_scale = 5\n",
    "\t•\tmax_scale = 25\n",
    "\t•\tincrement = 5\n",
    "\t•\tnum_bins = 4\n",
    "\t•\tThese parameters yield a feature vector of length 20, which provides a sweet spot between detail and conciseness.\n",
    "\t•\tIf the number of bins or the range of scales is too high, the feature vector becomes overly detailed (e.g., length 30+), leading to potential overfitting or redundant information. This caused the classifier to perform worse, likely due to overlapping scales introducing noise or redundant curvature calculations.\n",
    "\t•\tIf the feature vector is too short (e.g., length 10), the classifier lacks sufficient features to distinguish between classes effectively, leading to underfitting and poor performance.\n",
    "\t•\tI avoided using max_scale values that were too large because overly large circles would overlap significantly and distort the curvature calculations.\n",
    "\t•\tI found that using exactly 5 scale variations (5, 10, 15, 20, 25) worked best. Keeping fewer scale variations or significantly increasing the number resulted in decreased performance.\n",
    "\n",
    "- Discuss your choice of KNN classifier parameters and how you arrived at them (think about the same types of questions as in the previous point).\n",
    "\n",
    "\t_Your answer:_\t•\tI experimented with n_neighbors = 3 and n_neighbors = 5. Both values yielded similar results, but I chose n_neighbors = 5 as it provided more robust classification and reduced sensitivity to noise or outliers in the data.\n",
    "\t•\tThe performance of the KNN classifier aligns with its advantages:\n",
    "\t•\tWorks well when the distance between class means is large relative to class variance (as seen in the structured training data for leaves).\n",
    "\t•\tIt does not require extensive training time, allowing for quick experimentation with different parameters.\n",
    "\t•\tHigher values of n_neighbors (e.g., n_neighbors = 7 or 9) did not yield better results and sometimes slightly reduced the classification rate, as the voting became less class-specific.\n",
    "\n",
    "- Discuss the misclassified images.  Were there any classes that were particularly difficult to distinguish?  Is there anything unusual about any of the misclassified images that would cuase them to be misclassified?  If so, explain\n",
    "\n",
    "\t_Your answer:_\t•\tClass 3 was the most challenging to classify. Many of the test images in this class exhibited irregular structures:\n",
    "\t•\tSome had large holes or gaps in the boundary, leading to incomplete curvature calculations.\n",
    "\t•\tOthers had edges or incomplete shapes that did not resemble typical leaves, making it hard for the HoCS descriptors to capture distinctive features.\n",
    "\t•\tMisclassified images in Class 3 were often confused with Classes 1 and 2, which had better-defined leaf-like structures.\n",
    "\t•\tSpecific observations:\n",
    "\t•\tTest images with distorted boundaries or irregular shapes resulted in curvature values that overlapped with other classes.\n",
    "\t•\tFor instance, images like image_0186.png (classified as Class 1 instead of Class 3) had fragmented edges, leading to incorrect classifications.\n",
    "\t•\tThis difficulty could be partially addressed by preprocessing the images (e.g., smoothing boundaries or filling gaps) or by using additional texture-based descriptors to complement HoCS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
